{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# To set numpy to not print in exponential notation\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "cancer_df = pd.read_csv('dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for preprocessing dataset. note that it returns a copy of the dataset and doesn't modify the original dataset\n",
    "def preprocess(df_orig, to_standardize=False):\n",
    "    df = df_orig.copy()\n",
    "\n",
    "    # fill na values with mean in each column\n",
    "    for i, col in enumerate(df.columns[2:]):\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "\n",
    "    # standardize data wrt normal distribution, only if, to_standardize variable is set to True\n",
    "    if to_standardize == True:\n",
    "        for i, col in enumerate(df.columns[2:]):\n",
    "            df[col] = (df[col] - df[col].mean())/df[col].std()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_split_data(X, y, randomSeed = 0):\n",
    "    if randomSeed != 0:\n",
    "        np.random.seed(randomSeed)\n",
    "    arr_rand = np.random.rand(X.shape[0])\n",
    "    split = arr_rand < np.percentile(arr_rand, 67)\n",
    "\n",
    "    X_train = X[split]\n",
    "    y_train = y[split]\n",
    "    X_test =  X[~split]\n",
    "    y_test = y[~split]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A - Perceptron Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, D, alpha=1):\n",
    "        self.W = np.zeros(D+1)\n",
    "        self.alpha = alpha\n",
    "\n",
    "    # activation function = sign function\n",
    "\n",
    "    def step(self, x):\n",
    "        if np.isscalar(x):\n",
    "            return 1 if x > 0 else -1\n",
    "        else:\n",
    "            # just a fancy way to return 1 where x > 0 and -1 where not\n",
    "            return 2*(x > 0) + np.linspace(-1, -1, x.shape[0])\n",
    "\n",
    "    def fit(self, X, y, epochs=100):\n",
    "        # adding a column of ones in the input dataset. this is helpful for training with bias\n",
    "        X = np.c_[X, np.ones((X.shape[0]))]\n",
    "        for epoch in np.arange(0, epochs):\n",
    "            for (x, target) in zip(X, y):\n",
    "                prediction = np.dot(x, self.W)\n",
    "                if prediction*target <= 0:\n",
    "                    self.W = self.W + target*x\n",
    "\n",
    "    # this runs an infinite loop until the data points are linearly separable wrt W vector\n",
    "    def linear_fit(self, X, Y, epoch_lim = 0):\n",
    "        nrows = X.shape[0]\n",
    "        print(\"Total Points:\", nrows)\n",
    "        X = np.c_[X, np.ones((X.shape[0]))]\n",
    "\n",
    "        count = 1           # misclassified points count\n",
    "        epoch = 0\n",
    "        while count != 0:\n",
    "            count = 0\n",
    "            for i, (x, y) in enumerate(zip(X, Y)):\n",
    "                prediction = np.dot(x, self.W)\n",
    "                if prediction*y <= 0:\n",
    "                    count = count+1\n",
    "                    self.W = self.W + y*x\n",
    "            if epoch % 5000 == 0:\n",
    "                temp_output = 2*(np.dot(X, self.W) > 0) + np.linspace(-1, -1, X.shape[0])\n",
    "                tp, fp, tn, fn = self.checkStatistics(temp_output, Y)\n",
    "                \n",
    "                print(\"Epochs:\", epoch, \"\\t\\tMisclassified Points:\", count, \"\\tAccuracy:\", \"{0:.5f}\".format((tp+tn)/(tp+fp+tn+fn)), \"\\tRecall:\", \"{0:.5f}\".format(tp/(tp+fn)), \"\\tPrecision:\", \"{0:.5f}\".format(tp/(tp+fp)))\n",
    "            epoch += 1\n",
    "            if epoch_lim and epoch > epoch_lim:\n",
    "                break\n",
    "        if epoch <= epoch_lim:\n",
    "            print(\"Successfully classified in\", epoch, \"epochs!\")\n",
    "\n",
    "\n",
    "    # X is a matrix here. Predicts for all the points in X.\n",
    "    def predict(self, X):\n",
    "        # ensure our input is a matrix\n",
    "        X = np.atleast_2d(X)\n",
    "        X = np.c_[X, np.ones((X.shape[0]))]\n",
    "        return self.step(np.dot(X, self.W))\n",
    "\n",
    "\n",
    "    # x is a vector here. Predicts only for one point.\n",
    "    def predictOne(self, x):\n",
    "        # add 1 in the back of feature vector since we trained using bias.\n",
    "        toAdd = pd.Series([1])\n",
    "        x = pd.concat([x, toAdd])\n",
    "        return self.step(np.dot(x, self.W))\n",
    "\n",
    "    # returns back the true positives, false positives, true negatives, false negatives.\n",
    "    def checkStatistics(self, predicted, response):\n",
    "        tp = np.sum(np.logical_and(predicted == 1, response == 1))\n",
    "        fp = np.sum(np.logical_and(predicted == 1, response == -1))\n",
    "        tn = np.sum(np.logical_and(predicted == -1, response == -1))\n",
    "        fn = np.sum(np.logical_and(predicted == -1, response == 1))\n",
    "        return tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PM1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Points: 563\n",
      "Epochs: 0 \t\tMisclassified Points: 168 \tAccuracy: 0.77265 \tRecall: 0.95735 \tPrecision: 0.62928\n",
      "Epochs: 5000 \t\tMisclassified Points: 52 \tAccuracy: 0.90941 \tRecall: 0.75829 \tPrecision: 1.00000\n",
      "Epochs: 10000 \t\tMisclassified Points: 45 \tAccuracy: 0.91829 \tRecall: 0.80095 \tPrecision: 0.97688\n",
      "Epochs: 15000 \t\tMisclassified Points: 45 \tAccuracy: 0.90941 \tRecall: 0.76303 \tPrecision: 0.99383\n",
      "Epochs: 20000 \t\tMisclassified Points: 41 \tAccuracy: 0.90764 \tRecall: 0.75829 \tPrecision: 0.99379\n",
      "Epochs: 25000 \t\tMisclassified Points: 37 \tAccuracy: 0.92007 \tRecall: 0.79147 \tPrecision: 0.99405\n",
      "Epochs: 30000 \t\tMisclassified Points: 35 \tAccuracy: 0.92895 \tRecall: 0.82464 \tPrecision: 0.98305\n",
      "Epochs: 35000 \t\tMisclassified Points: 38 \tAccuracy: 0.90053 \tRecall: 0.73460 \tPrecision: 1.00000\n",
      "Epochs: 40000 \t\tMisclassified Points: 38 \tAccuracy: 0.89876 \tRecall: 0.73460 \tPrecision: 0.99359\n",
      "Epochs: 45000 \t\tMisclassified Points: 35 \tAccuracy: 0.93250 \tRecall: 0.83886 \tPrecision: 0.97790\n",
      "Epochs: 50000 \t\tMisclassified Points: 38 \tAccuracy: 0.92007 \tRecall: 0.79147 \tPrecision: 0.99405\n"
     ]
    }
   ],
   "source": [
    "# this just sets the blank/nan values to mean values\n",
    "# df = preprocess(cancer_df)\n",
    "\n",
    "# this drops the rows with nan values\n",
    "df = cancer_df.copy()\n",
    "df.dropna(axis = 0, inplace=True)\n",
    "\n",
    "# Setting Malignant as the positive class and Benign as the negative class\n",
    "df['diagnosis'] = df['diagnosis'].replace('B', -1)\n",
    "df['diagnosis'] = df['diagnosis'].replace('M', 1)\n",
    "\n",
    "df_input = df[df.columns[2:]]\n",
    "df_response = df[df.columns[1]]\n",
    "features_n = len(df.columns)-2\n",
    "\n",
    "PM1 = Perceptron(features_n)\n",
    "PM1.linear_fit(df_input, df_response, 50_000)\n",
    "\n",
    "\n",
    "# For unnormalized data, when tried to linearly fit:\n",
    "# At 2,50,000 epochs -> 21 points are being misclassified. \n",
    "# At 60,40,000 epochs -> 23 still misclassified.\n",
    "# But normalized data is getting linearly fit in 2,00,293 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 1 112 6\n",
      "Accuracy: 0.9627659574468085\n",
      "Recall: 0.92\n",
      "Precision: 0.9857142857142858\n"
     ]
    }
   ],
   "source": [
    "df = preprocess(cancer_df)\n",
    "df['diagnosis'] = df['diagnosis'].replace('B', -1)\n",
    "df['diagnosis'] = df['diagnosis'].replace('M', 1)\n",
    "features_n = len(df.columns)-2\n",
    "df1_input, df1_response, df2_input, df2_response = shuffle_split_data(df[df.columns[2:]], df[df.columns[1]], 12345678)\n",
    "\n",
    "PM2 = Perceptron(features_n)\n",
    "PM2.fit(df1_input, df1_response, 1000)\n",
    "df2_predicted = PM2.predict(df2_input)\n",
    "tp, fp, tn, fn = PM2.checkStatistics(df2_predicted, df2_response)\n",
    "print(tp, fp, tn, fn)\n",
    "print(\"Accuracy:\", (tp+tn)/(tp+tn+fp+fn))\n",
    "print(\"Recall:\", (tp)/(tp+fn))\n",
    "print(\"Precision:\", (tp)/(tp+fp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PM3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9840425531914894\n",
      "Recall: 0.9714285714285714\n",
      "Precision: 0.9855072463768116\n"
     ]
    }
   ],
   "source": [
    "df = preprocess(cancer_df, True)\n",
    "df['diagnosis'] = df['diagnosis'].replace('B', -1)\n",
    "df['diagnosis'] = df['diagnosis'].replace('M', 1)\n",
    "features_n = len(df.columns)-2\n",
    "df1_input, df1_response, df2_input, df2_response = shuffle_split_data(df[df.columns[2:]], df[df.columns[1]])\n",
    "\n",
    "PM3 = Perceptron(features_n)\n",
    "PM3.fit(df1_input, df1_response, 1000)\n",
    "df2_predicted = PM3.predict(df2_input)\n",
    "tp, fp, tn, fn = PM3.checkStatistics(df2_predicted, df2_response)\n",
    "print(\"Accuracy:\", (tp+tn)/(tp+tn+fp+fn))\n",
    "print(\"Recall:\", (tp)/(tp+fn))\n",
    "print(\"Precision:\", (tp)/(tp+fp))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PM4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 1 112 6\n",
      "Accuracy: 0.9627659574468085\n",
      "Recall: 0.92\n",
      "Precision: 0.9857142857142858\n"
     ]
    }
   ],
   "source": [
    "df = preprocess(cancer_df, False)\n",
    "df['diagnosis'] = df['diagnosis'].replace('B', -1)\n",
    "df['diagnosis'] = df['diagnosis'].replace('M', 1)\n",
    "features_n = len(df.columns)-2\n",
    "\n",
    "df_input = df.iloc[:, 2:]\n",
    "df_response = df.iloc[:, 1]\n",
    "df_input = df_input.sample(frac=1, axis = 1)\n",
    "\n",
    "df1_input, df1_response, df2_input, df2_response = shuffle_split_data(df_input, df_response, 12345678)\n",
    "\n",
    "PM4 = Perceptron(features_n)\n",
    "PM4.fit(df1_input, df1_response, 1000)\n",
    "df2_predicted = PM4.predict(df2_input)\n",
    "tp, fp, tn, fn = PM4.checkStatistics(df2_predicted, df2_response)\n",
    "print(tp, fp, tn, fn)\n",
    "print(\"Accuracy:\", (tp+tn)/(tp+tn+fp+fn))\n",
    "print(\"Recall:\", (tp)/(tp+fn))\n",
    "print(\"Precision:\", (tp)/(tp+fp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
